<!DOCTYPE html>
<html>

<head lang="en">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-4GD306FBRX"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-4GD306FBRX');
    </script>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>VA2CONTACT: Visual-auditory Extrinsic Contact Estimation</title>

    <meta name="description" content="VA2CONTACT: Visual-auditory Extrinsic Contact Estimation">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://va2contact.github.io/img/teaser.jpg">
    <meta property="og:image:type" content="image/jpg">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://va2contact.github.io/" />
    <meta property="og:title" content="VA2CONTACT: Visual-auditory Extrinsic Contact Estimation" />
    <meta property="og:description"
        content="VA2CONTACT is a novel visual-auditory method for extrinsic contact estimation that integrates global scene information from vision with local contact cues obtained through active audio sensing." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="VA2CONTACT: Visual-auditory Extrinsic Contact Estimation" />
    <meta name="twitter:description"
        content="VA2CONTACT is a novel visual-auditory method for extrinsic contact estimation that integrates global scene information from vision with local contact cues obtained through active audio sensing." />
    <meta name="twitter:image" content="https://va2contact.github.io/img/teaser.jpg" />

    <link rel="icon" href="favicon.ico">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
    <script defer src="js/app.js"></script>
</head>

<body style="padding: 5%; padding-top: min(15px, 5%); padding-bottom: min(5px, 5%); width: 100%">
    <div class="container-lg text-center" style="max-width: 1500px; margin: auto;" id="main">
        <header role="banner">
            <div class="row">
                <h2 class="col-md-12 text-center">
                    <b>VA2CONTACT:</b> Visual-auditory Extrinsic Contact Estimation</br>
                </h2>
            </div>
            <div class="row text-center">
                <div class="col-md-3">
                </div>
                <div class="container-fluid text-center">
                    <ul class="list-inline" style="white-space: nowrap; margin:0px 0px 0px 0px;">
                        <li><a style="font-size: calc(min(3vw, 15px))" href="mailto:yixili@umich.edu">Xili Yi¹</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="mailto:jayjun@umich.edu">Jayjun Lee¹</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="mailto:nfz@umich.edu">Nima Fazeli¹</a></li>
                    </ul>
                </div>
                <div class="container-fluid text-center">
                    <ul class="list-inline" style="white-space: nowrap; margin:0px 0px 0px 0px;">
                        <li><a style="font-size: calc(min(3vw, 15px))">¹University of Michigan</a></li>
                    </ul>
                </div>
            </div>
            <div class="row text-center">
                <div class="d-flex justify-content-center" style="gap: 15px;">
                    <a class="button" style="width: 200px; font-size: 15px;" href="https://arxiv.org/abs/2409.14608" target="_blank">
                        <span class="icon">
                            <i class="fa fa-file-pdf-o"></i>
                        </span>
                        <span>Paper</span>
                    </a>
                    <a class="button" style="width: 200px; font-size: 15px; background-color: #6c757d; cursor: not-allowed;" disabled>
                        <span class="icon">
                            <i class="fa fa-github"></i>
                        </span>
                        <span>Code (Coming Soon)</span>
                    </a>
                    <a class="button" style="width: 200px; font-size: 15px; background-color: #6c757d; cursor: not-allowed;" disabled>
                        <span class="icon">
                            <i class="fa fa-database"></i>
                        </span>
                        <span>Data (Coming Soon)</span>
                    </a>
                </div>
            </div>
        </header>

        <main role="main">
            <!-- Teaser Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <img src="img/teaser.jpg" alt="VA2CONTACT Teaser" class="img-fluid" style="width: 60%; margin: 0 auto 20px auto; display: block;">
                </div>
            </div>

            <!-- Video Demo Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Video Demonstration</h3>
                    <div class="row">
                        <div class="col-md-8 offset-md-2">
                            <div class="ratio ratio-16x9" style="margin-bottom: 20px;">
                                <video controls width="100%" poster="img/video_thumbnail.jpg">
                                    <source src="videos/VA2C_video.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <p class="text-center">Contact Estimation Demo</p>
                        </div>
                    </div>
                </div>
            </div><br>

            <!-- TL;DR Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2 rounded highlight-section">
                    <h6 style="text-align: center; color:rgb(0, 0, 0)"><strong>TL;DR</strong>: VA2CONTACT integrates visual and active audio sensing to accurately detect extrinsic contacts between a grasped object and the environment, even in occluded or ambiguous scenarios, with zero-shot sim-to-real transfer.</h6>
                </div>
            </div><br><br>

            <!-- Abstract Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Abstract</h3>
                    <p style="text-align: justify;">
                        Robust manipulation often hinges on a robot's ability to perceive extrinsic contacts—contacts between a grasped object and its surrounding environment. However, these contacts are difficult to observe through vision alone due to occlusions, limited resolution, and ambiguous near-contact states. In this paper, we propose a visual-auditory method for extrinsic contact estimation that integrates global scene information from vision with local contact cues obtained through active audio sensing. Our approach equips a robotic gripper with contact microphones and conduction speakers, enabling the system to emit and receive acoustic signals through the grasped object to detect external contacts. We train our perception pipeline entirely in simulation and zero-shot transfer to the real-world. To bridge the sim-to-real gap, we introduce a real-to-sim audio hallucination technique, injecting real-world audio samples into simulated scenes with ground-truth contact labels. The resulting multimodal model accurately estimates both the location and size of extrinsic contacts across a range of cluttered and occluded scenarios. We further demonstrate that explicit contact prediction significantly improves policy learning for downstream contact-rich manipulation tasks.
                    </p>
                </div>
            </div><br>

            <!-- Method Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Method</h3>
                    <p style="text-align: justify;">
                        Our method addresses the challenges of extrinsic contact estimation by combining the strengths of multiple sensing modalities. The system consists of three main components that work together to accurately detect and localize contacts between a grasped object and the environment.
                    </p>
                    <div class="row">
                        <div class="col-md-12 text-center">
                            <img src="img/main_v9_page-0001.jpg" alt="Method Overview" class="img-fluid" style="width: 80%; margin: 20px auto;">
                        </div>
                    </div>
                    <p style="text-align: justify;">
                        <strong>1. Real-to-Sim Audio Hallucination:</strong> Since dense contact maps are difficult to obtain in the real world, we train entirely in simulation using ground-truth contact labels, and bridge the gap to real-world acoustics using an audio hallucination technique. To overcome the challenge of simulating audio, we introduce an audio hallucination technique. In the real world, we collect audio signals paired with labeled contact types using teleoperated wiping over various surfaces. In simulation, we generate contact maps and randomly sample real spectrograms corresponding to their type—bridging real-world acoustic signals and simulated labels.
                    </p>
                    <p style="text-align: justify;">
                        <strong>2. VA2Contact:</strong> VA2Contact—that predicts a dense contact probability map from depth, optical flow, and an audio spectrogram.
                    </p>
                    <p style="text-align: justify;">
                        <strong>3. Real-World Contact-Aware Policy:</strong> We freeze the VA2Contact model and use its contact predictions—along with camera input—as observations for a Diffusion Policy.

                    </p>
                </div>
            </div><br>

            <!-- Features Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Key Features</h3>
                    <div class="row">
                        <div class="col-md-4">
                            <div class="feature-box">
                                <h4>Active Audio Sensing</h4>
                                <p>Uses conduction speakers and contact microphones to detect contacts even in static scenarios and when visual occlusions are present, providing rich information about contact dynamics that is often invisible to visual sensors.</p>
                            </div>
                        </div>
                        <div class="col-md-4">
                            <div class="feature-box">
                                <h4>Occlusion Handling</h4>
                                <p>Maintains high performance even when contact points are visually occluded or in ambiguous near-contact scenarios, thanks to the complementary information provided by audio signals that can travel through solid objects.</p>
                            </div>
                        </div>
                        <div class="col-md-4">
                            <div class="feature-box">
                                <h4>Sim-to-Real Transfer</h4>
                                <p>Our real-to-sim audio hallucination technique enables zero-shot transfer from simulation to real-world scenarios, eliminating the need for real-world training data with contact labels while maintaining robust performance.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div><br>

            <!-- Results Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Results</h3>
                    <p style="text-align: justify;">
                        We evaluated VA2CONTACT on a variety of contact estimation tasks in real-world environments, comparing it against the vision-only Im2Contact method and ablation studies. Our experiments demonstrate that our multimodal approach significantly outperforms vision-only methods, especially in challenging scenarios.
                    </p>
                    <div class="row">
                        <div class="col-md-12 text-center">
                            <img src="img/VA2C_result.png" alt="Experimental Results" class="img-fluid" style="width: 80%; margin: 20px auto;">
                        </div>
                    </div>
                    <p style="text-align: justify;">
                        Key findings include:
                    </p>
                    <ul style="text-align: left;">
                        <li>Higher recall and F1 scores in general contact detection, indicating superior ability to detect true contacts with fewer false negatives</li>
                        <li>Accurate contact detection even in heavily occluded scenarios where vision-only methods fail</li>
                        <li>Better performance in ambiguous near-contact scenarios where visual information is insufficient</li>
                        <li>Successful zero-shot transfer from simulation to real-world without additional training</li>
                        <li>Improved performance in downstream manipulation tasks: a contact-aware diffusion policy for a wiping task achieved 8/10 success rate compared to 4/10 for a vision-only baseline</li>
                    </ul>
                </div>
            </div><br>

            <!-- Team Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Team</h3>
                    <div class="row">
                        <div class="col-md-4 text-center">
                            <div style="display: flex; flex-direction: column; align-items: center; justify-content: center;">
                                <img src="img/xili.jpg" alt="Xili Yi" class="img-fluid rounded-circle" style="width: 150px; height: 150px; object-fit: cover; margin-bottom: 15px;">
                                <h4 style="text-align: center; width: 100%;">Xili Yi</h4>
                                <p style="text-align: center; margin-bottom: 5px;">Department of Robotics</p>
                                <p style="text-align: center; margin-bottom: 5px;">University of Michigan</p>
                                <p style="text-align: center;"><a href="mailto:yixili@umich.edu">yixili@umich.edu</a></p>
                            </div>
                        </div>
                        <div class="col-md-4 text-center">
                            <div style="display: flex; flex-direction: column; align-items: center; justify-content: center;">
                                <img src="img/jayjun.jpg" alt="Jayjun Lee" class="img-fluid rounded-circle" style="width: 150px; height: 150px; object-fit: cover; margin-bottom: 15px;">
                                <h4 style="text-align: center; width: 100%;">Jayjun Lee</h4>
                                <p style="text-align: center; margin-bottom: 5px;">Department of Robotics</p>
                                <p style="text-align: center; margin-bottom: 5px;">University of Michigan</p>
                                <p style="text-align: center;"><a href="mailto:jayjun@umich.edu">jayjun@umich.edu</a></p>
                            </div>
                        </div>
                        <div class="col-md-4 text-center">
                            <div style="display: flex; flex-direction: column; align-items: center; justify-content: center;">
                                <img src="img/nima.png" alt="Nima Fazeli" class="img-fluid rounded-circle" style="width: 150px; height: 150px; object-fit: cover; margin-bottom: 15px;">
                                <h4 style="text-align: center; width: 100%;">Nima Fazeli</h4>
                                <p style="text-align: center; margin-bottom: 5px;">Department of Robotics</p>
                                <p style="text-align: center; margin-bottom: 5px;">University of Michigan</p>
                                <p style="text-align: center;"><a href="mailto:nfz@umich.edu">nfz@umich.edu</a></p>
                            </div>
                        </div>
                    </div>
                </div>
            </div><br>

            <!-- Citation Section - Commented out
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Citation</h3>
                    <div class="highlight-section">
                        <pre style="text-align: left; background: none; border: none; padding: 10px;">
@inproceedings{yi2025va2contact,
  title={VA2CONTACT: Visual-auditory Extrinsic Contact Estimation},
  author={Yi, Xili and Lee, Jayjun and Fazeli, Nima},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2025}
}
                        </pre>
                    </div>
                </div>
            </div><br>
            -->

            <!-- Contact Section -->
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3>Contact</h3>
                    <p>
                        For questions about the project, please contact <a href="mailto:yixili@umich.edu">Xili Yi</a>, <a href="mailto:jayjun@umich.edu">Jayjun Lee</a> or <a href="mailto:nfz@umich.edu">Nima Fazeli</a>.
                    </p>
                </div>
            </div>
        </main>

        <footer class="mt-5 pt-5 text-center text-muted">
            <p>© 2025 VA2CONTACT Project | University of Michigan</p>
        </footer>
    </div>
</body>

</html>
